# Machine Learning Journey

This repository documents my process of learning Machine Learning step by step.  
Each notebook focuses on one concept, from basic data preprocessing to model building and evaluation.
The goal is to understand ML concepts step-by-step, from basic data handling to building models using `scikit-learn`.

---

## üìò Contents

| No. | Topic | Description |
|-----|--------|-------------|
| 1 | Missing Values | Handling missing data using pandas and sklearn |
| 2 | Encoding | Applying Label Encoding and One-Hot Encoding |
| 3 | Outliers | Detecting and treating outliers in datasets |
| 4 | Standardization | Scaling features using StandardScaler |
| 5 | Normalization | Normalizing numerical features for uniform range |
| 6 | Duplicate Data | Finding and removing duplicate entries |
| 7 | Function Transformation | Applying log, sqrt, and power transformations |
| 8 | Feature Selection | Selecting important features using statistical methods |
| 9 | Train Test Split | Splitting data into training and testing sets |
| 10 | Linear Regression | Building and evaluating a simple linear regression model |
| 11 | Polynomial Regression | Extending regression to nonlinear relationships |
| 12 | Regularization (House Price) | Applying Lasso and Ridge to control overfitting |
| 13 | Logistic Regression | Implementing logistic regression for classification |
| 14 | Polynomial Logistic Distribution | Exploring polynomial logistic models |
| 15 | Multiclass Classification | Handling more than two output classes |
| 16 | Confusion Matrix | Evaluating classification performance |
| 17 | Imbalanced Data | Techniques for handling class imbalance |
| 18 | Naive Bayes | Implementing Gaussian Naive Bayes classifier |
| 19 | Decision Tree (Classification) | Implementing and visualizing Decision Tree Classifier |
| 20 | Decision Tree (Regression) | Using Decision Tree for regression tasks |
| 21 | K-Nearest Neighbor (KNN) | Implementing KNN algorithm for classification |
| 22 | Support Vector Machine (SVM) | Implementing SVM for classification tasks |
| 23 | Hyperparameter Tuning | Improving model performance using GridSearchCV |
| 24 | Cross Validation | Evaluating model reliability with K-Fold Cross Validation |
| 25 | K-Means Clustering | Unsupervised learning with K-Means algorithm |
| 26 | Hierarchical Clustering | Visualizing hierarchical relationships using dendrograms |
| 27 |  |  |
| More to come soon... |
---

## üß© Tech Stack

- Python  
- Jupyter Notebook  
- NumPy, Pandas, Matplotlib, Seaborn  
- Scikit-learn  

---
## üß† Future Plans

- Add Random Forest, SVM, and KNN
- Explore Clustering (K-Means, Hierarchical)
- Include PCA and feature reduction techniques
- Apply cross-validation and hyperparameter tuning
- Create end-to-end ML projects (e.g., spam detection, price prediction)

---

## ‚öôÔ∏è Setup

```bash
# Clone this repository
git clone https://github.com/your-username/machine-learning-journey.git

# Move into the project folder
cd machine-learning-journey

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter Notebook
jupyter notebook
